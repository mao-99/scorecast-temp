{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train my model, I need the data in a wide format so the model can accurately consider both teams involved in a matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_df = pd.read_json('../processed_data/pl_data_dt.json')\n",
    "\n",
    "matchup_df['actual_result'] = np.where(matchup_df['home_goals'] > matchup_df['away_goals'], 1, 0)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, min_samples_split=2, min_samples_leaf=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the probability:  [[0.53188015 0.46811985]\n",
      " [0.54673693 0.45326307]\n",
      " [0.53792494 0.46207506]\n",
      " ...\n",
      " [0.49301435 0.50698565]\n",
      " [0.54673693 0.45326307]\n",
      " [0.58922514 0.41077486]]\n",
      "Maximum probability 0.6002146370249782\n",
      "Model Performance:\n",
      "\n",
      "Accuracy: 0.6406480117820325\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Home Win       0.61      0.92      0.73       367\n",
      "Away Win/Draw       0.76      0.32      0.45       312\n",
      "\n",
      "     accuracy                           0.64       679\n",
      "    macro avg       0.69      0.62      0.59       679\n",
      " weighted avg       0.68      0.64      0.60       679\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                             feature  importance\n",
      "14              home_shot_efficiency    0.355237\n",
      "3     home_shots_on_goal_rolling_avg    0.317073\n",
      "2             home_shots_rolling_avg    0.146341\n",
      "0             home_goals_rolling_avg    0.121951\n",
      "9     away_shots_on_goal_rolling_avg    0.059397\n",
      "1    home_conceded_goals_rolling_avg    0.000000\n",
      "4   home_conversion_rate_rolling_avg    0.000000\n",
      "5      home_target_ratio_rolling_avg    0.000000\n",
      "6             away_goals_rolling_avg    0.000000\n",
      "7    away_conceded_goals_rolling_avg    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Define features for prediction\n",
    "feature_columns = [\n",
    "    # Context Features\n",
    "    \n",
    "    # Home Team Form (Rolling Averages)\n",
    "    'home_goals_rolling_avg', 'home_conceded_goals_rolling_avg',\n",
    "    'home_shots_rolling_avg', \n",
    "    # 'home_conceded_shots_rolling_avg',\n",
    "    'home_shots_on_goal_rolling_avg', \n",
    "    # 'home_conceded_shots_on_goal_rolling_avg',\n",
    "    # 'home_goalkeeper_saves_rolling_avg', \n",
    "    # 'home_blocked_shots_rolling_avg',\n",
    "    'home_conversion_rate_rolling_avg', \n",
    "    'home_target_ratio_rolling_avg',\n",
    "    \n",
    "    # Away Team Form (Rolling Averages)\n",
    "    'away_goals_rolling_avg', 'away_conceded_goals_rolling_avg',\n",
    "    'away_shots_rolling_avg', \n",
    "    # 'away_conceded_shots_rolling_avg',\n",
    "    'away_shots_on_goal_rolling_avg', \n",
    "    # 'away_conceded_shots_on_goal_rolling_avg',\n",
    "    # 'away_goalkeeper_saves_rolling_avg', 'away_blocked_shots_rolling_avg',\n",
    "    'away_conversion_rate_rolling_avg', 'away_target_ratio_rolling_avg',\n",
    "    \n",
    "    # # Current Game Attack Strength\n",
    "    # 'home_shot_creation_ratio', 'home_target_ratio', 'home_conversion_rate',\n",
    "    # 'away_shot_creation_ratio', 'away_target_ratio', 'away_conversion_rate',\n",
    "    \n",
    "    # # Possession and Control\n",
    "    # 'home_poss', 'away_poss',\n",
    "    # 'home_chances', 'away_chances',\n",
    "    # 'home_dangerous_attacks', 'away_dangerous_attacks',\n",
    "    \n",
    "    # Efficiency Metrics (Derived)\n",
    "    f'home_danger_ratio', # home_dangerous_attacks / home_attacks\n",
    "    f'away_danger_ratio', # away_dangerous_attacks / away_attacks\n",
    "    f'home_shot_efficiency', # home_shots_on_goal / home_shots\n",
    "    f'away_shot_efficiency', # away_shots_on_goal / away_shots\n",
    "]\n",
    "\n",
    "# Create derived features\n",
    "matchup_df['home_danger_ratio'] = matchup_df['home_dangerous_attacks'] / matchup_df['home_attacks'].replace(0, 1)\n",
    "matchup_df['away_danger_ratio'] = matchup_df['away_dangerous_attacks'] / matchup_df['away_attacks'].replace(0, 1)\n",
    "matchup_df['home_shot_efficiency'] = matchup_df['home_shots_on_goal'] / matchup_df['home_shots'].replace(0, 1)\n",
    "matchup_df['away_shot_efficiency'] = matchup_df['away_shots_on_goal'] / matchup_df['away_shots'].replace(0, 1)\n",
    "\n",
    "# Prepare features and targets\n",
    "X = matchup_df[feature_columns]\n",
    "y_result = matchup_df['actual_result']  #1: Home Win, 2: Away Win\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_result_train, y_result_test = train_test_split(\n",
    "    X_scaled, y_result, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "# 1. Match Result Predictor (Classification)\n",
    "result_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    min_samples_split=40,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    "    ,criterion='entropy',\n",
    "    ccp_alpha=0.05\n",
    ")\n",
    "\n",
    "# Train model\n",
    "result_model.fit(X_train, y_result_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = result_model.predict(X_test)\n",
    "y_pred_proba = result_model.predict_proba(X_test)\n",
    "print(\"This is the probability: \", y_pred_proba)\n",
    "print(\"Maximum probability\", np.max(y_pred_proba[:,0]))\n",
    "# Evaluate\n",
    "print(\"Model Performance:\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_result_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_result_test, y_pred, \n",
    "                          target_names=['Home Win', 'Away Win/Draw']))\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': result_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "\n",
      "Accuracy: 0.6504424778761062\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Home Win       0.62      0.92      0.74      1473\n",
      "Away Win/Draw       0.78      0.33      0.46      1239\n",
      "\n",
      "     accuracy                           0.65      2712\n",
      "    macro avg       0.70      0.62      0.60      2712\n",
      " weighted avg       0.69      0.65      0.61      2712\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                             feature  importance\n",
      "14              home_shot_efficiency    0.355237\n",
      "3     home_shots_on_goal_rolling_avg    0.317073\n",
      "2             home_shots_rolling_avg    0.146341\n",
      "0             home_goals_rolling_avg    0.121951\n",
      "9     away_shots_on_goal_rolling_avg    0.059397\n",
      "1    home_conceded_goals_rolling_avg    0.000000\n",
      "4   home_conversion_rate_rolling_avg    0.000000\n",
      "5      home_target_ratio_rolling_avg    0.000000\n",
      "6             away_goals_rolling_avg    0.000000\n",
      "7    away_conceded_goals_rolling_avg    0.000000\n"
     ]
    }
   ],
   "source": [
    "y_pred = result_model.predict(X_train)\n",
    "y_pred_proba = result_model.predict_proba(X_train)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Model Performance:\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_result_train, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_result_train, y_pred, \n",
    "                          target_names=['Home Win', 'Away Win/Draw']))\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': result_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45949926362297494\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       169\n",
      "           1       0.46      1.00      0.63       312\n",
      "           2       0.00      0.00      0.00       198\n",
      "\n",
      "    accuracy                           0.46       679\n",
      "   macro avg       0.15      0.33      0.21       679\n",
      "weighted avg       0.21      0.46      0.29       679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your data\n",
    "matchup_df = pd.read_json('../processed_data/pl_data.json')\n",
    "\n",
    "# Prepare your features and target variable\n",
    "X = matchup_df[['home_goals', 'away_goals']]  # Example features\n",
    "y = np.where(matchup_df['home_goals'] > matchup_df['away_goals'], 1, \n",
    "             np.where(matchup_df['home_goals'] < matchup_df['away_goals'], 2, 0))  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the DummyClassifier\n",
    "dummy_clf = DummyClassifier()\n",
    "\n",
    "# Train the DummyClassifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the DummyClassifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45685840707964603\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       614\n",
      "           1       0.46      1.00      0.63      1239\n",
      "           2       0.00      0.00      0.00       859\n",
      "\n",
      "    accuracy                           0.46      2712\n",
      "   macro avg       0.15      0.33      0.21      2712\n",
      "weighted avg       0.21      0.46      0.29      2712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = dummy_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the DummyClassifier\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "report = classification_report(y_train, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'trained_model.sav'\n",
    "pickle.dump(result_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min_sample_split = 15, min_sample_leaf = 15 => 81% (train), 68%(test)\n",
    "# min_sample_split = 20, min_sample_leaf = 10 => 84% (train), 70%(test)\n",
    "\n",
    "# min_sample_split = 40, min_sample_leaf = 5 => 83% (train), 70%(test)\n",
    "# min_sample_split = 40, min_sample_leaf = 15 => 80% (train), 68%(test)\n",
    "\n",
    "# criterion='entropy':\n",
    "# min_sample_split = 40, min_sample_leaf = 15 => 80% (train), 69%(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_df.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
